{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jansoe/ANN/blob/main/GPT_Klassifikation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcEczAKH62F6"
   },
   "source": [
    "# GPT-Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvezSWat7CiT"
   },
   "source": [
    "#### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry0M9QvTOLHP",
    "outputId": "c28b8272-6c2c-4109-ad09-b00f5a34c836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wuensche\\appdata\\roaming\\python\\python39\\site-packages (from openai) (1.9.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wuensche\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e15txcqaOUPg"
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y0vZ-V3ImB0-"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# from google.colab import userdata\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # api_key=\"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\",\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "jvhMcU9RX2Dp",
    "outputId": "571d2e5a-8d1f-4fd0-f30e-227847e9ee46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir still waiting. Just hit one hour.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir although I'm not happy you Cance...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@SouthwestAir Hello - been on hold for extreme...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment\n",
       "0         0    @SouthwestAir still waiting. Just hit one hour.        NaN\n",
       "1         1  @SouthwestAir although I'm not happy you Cance...        NaN\n",
       "2         2  @SouthwestAir Hello - been on hold for extreme...        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"tweets.tsv\", delimiter='\\t')\n",
    "tweets['sentiment'] = np.nan\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vJH3R6jthBQk"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\\\n",
    "Your task is to labelize customer tweets in context of an airline.\n",
    "The categories from which you can choose are the following: 'Overall Customer Experience', 'Customer Service'\n",
    "'Website', 'Hotline', 'Check-In', 'Social Media', 'Other (CS)', 'Flight experience', 'Baggage',\n",
    "'Flight cancelled', 'Flight delayed', 'Other (FE)' and 'Other'. \n",
    "After the labelizing task return me a top 3 highest labels from highest probability over 2nd highest probability to 3rd highest probability\n",
    "with a scala from 0 to 1 and give me your key features from which your final decision arised.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dxvEKkqzfQtf"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "            \"description\": \"Returns the 3 top highest probabilities for the labeling task.\",\n",
    "            \"name\": \"reasoning_decision\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"class_probabilities\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"class1\": {\n",
    "                              \"type\": \"string\"  \n",
    "                            },\n",
    "                            \"class1_prob\": {\n",
    "                              \"type\": \"number\",\n",
    "                              \"minimum\": 0.0,\n",
    "                              \"maximum\": 1.0\n",
    "                            },\n",
    "                            \"class2_prob\": {\n",
    "                              \"type\": \"number\",\n",
    "                              \"minimum\": 0.0,\n",
    "                              \"maximum\": 1.0\n",
    "                            },\n",
    "                            \"class3_prob\": {\n",
    "                              \"type\": \"number\",\n",
    "                              \"minimum\": 0.0,\n",
    "                              \"maximum\": 1.0\n",
    "                            },\n",
    "                            # Add more classes as needed\n",
    "                          },\n",
    "                          \"additionalProperties\": False, \n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"class_probabilities\", \"predicted_class\"],\n",
    "            }\n",
    "       }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg_ex1 = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": tweets.tweet.values[0],\n",
    "}\n",
    "\n",
    "assistant_msg_ex1 = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"\"\"\\\n",
    "        Summary: Extremely long hold, boarding pass issue, multiple attempts.\n",
    "        Customer Emotions: Frustration, impatience.\n",
    "        Sentiment Rating: -0.8.\n",
    "        Now, I will call the `dump_extracted_data` function with the obtained sentiment value.\n",
    "        \"\"\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": \"call_ex1\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"arguments\": \"{\\\"sentiment\\\":-0.8}\",\n",
    "                \"name\": \"dump_extracted_data\",\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "tool_msg = {\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": \"call_ex1\",\n",
    "    \"content\": \"\"\"{\"saved\": \"true\"}\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERAifvdPZpys",
    "outputId": "3b679229-83c3-4d95-8d3f-c9035a3ebfba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting==========\n",
      "\n",
      "```reasoning_decision\n",
      "text = \"@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting\"\n",
      "```\n",
      "This tweet expresses frustration about a delay in boarding, implying a dissatisfaction with the flight experience based on the waiting time. The key features leading to this classification are the mention of \"waiting\" and the reference to the boarding process.\n",
      "!!! No tool call !!!\n",
      "\n",
      "==========@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting==========\n",
      "\n",
      "It seems like the tweet is expressing frustration about a delay. The customer is unhappy with the boarding process and the waiting time. I would labelize it as 'Flight delayed' (0.7), 'Customer Service' (0.2), and 'Other (CS)' (0.1).\n",
      "\n",
      "Key features:\n",
      "- The mention of \"waiting\" and \"time\" indicates a delay issue.\n",
      "- The dissatisfaction with the boarding process relates to customer service.\n",
      "- The use of \"logically\" suggests an expectation that was not met, falling into the \"Other (CS)\" category.\n",
      "!!! No tool call !!!\n",
      "\n",
      "==========@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting==========\n",
      "\n",
      "reasoning_decision(Overall Customer Experience, Customer Service, Other (CS), Flight delayed)\n",
      "The tweet expresses dissatisfaction with the time spent waiting and implies a delay in the flight. This indicates an impact on the overall customer experience and suggests a potential customer service issue. The mention of \"waiting\" and \"board\" points towards a delay in the flight, hence the top labels are 'Flight delayed' with a score of 0.9, followed by 'Overall Customer Experience' with a score of 0.7, and 'Customer Service' with a score of 0.5.\n",
      "!!! No tool call !!!\n",
      "\n",
      "==========@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting==========\n",
      "\n",
      "Reasoning:\n",
      "The customer's tweet is expressing frustration about a delay caused by a problem that should have been addressed before boarding. This falls under the category of 'Flight delayed'.\n",
      "\n",
      "Using the reasoning_decision function:\n",
      "- 'Flight delayed' - Probability: 0.9\n",
      "- 'Overall Customer Experience' - Probability: 0.6\n",
      "- 'Customer Service' - Probability: 0.4\n",
      "\n",
      "Key features leading to the decision:\n",
      "- The tweet clearly indicates frustration about a delay before boarding, which aligns with the 'Flight delayed' category.\n",
      "- The customer's statement about the time wasted further supports the decision for 'Flight delayed'.\n",
      "!!! No tool call !!!\n",
      "\n",
      "==========@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting==========\n",
      "\n",
      "```reasoning_decision\n",
      "text = \"@SouthwestAir Logically you would think you check all that before you have people board. I could've drove home in the time I've been waiting\"\n",
      "```\n",
      "\n",
      "!!! No tool call !!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet2analyze = 20\n",
    "\n",
    "parameter = dict(\n",
    "    #model=\"gpt-4-1106-preview\",\n",
    "    #model = \"gpt-4-0613\",\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    # tools = tools,\n",
    "    #temperature = 0,\n",
    "    #top_p = 0,\n",
    "    #seed = 42\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    tweet  = tweets.loc[tweet2analyze, \"tweet\"]\n",
    "    print(\"=\"*10 + tweet + \"=\" *10, end='\\n\\n')\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        # user_msg_ex1,\n",
    "        # assistant_msg_ex1,\n",
    "        # tool_msg,\n",
    "        {\"role\": \"user\", \"content\": tweet}\n",
    "    ]\n",
    "    response = client.chat.completions.create(messages=messages, **parameter)\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    if not(response.choices[0].message.tool_calls):\n",
    "        print(\"!!! No tool call !!!\", end='\\n\\n')\n",
    "    else:\n",
    "        print(response.choices[0].message.tool_calls[0].function.arguments, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3KLcENbRhj5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyqNaYqMBveq4JFnXPUsrd",
   "include_colab_link": true,
   "mount_file_id": "1yq5YjFWWwJ_74FOd65ogJsFTVVdmk-73",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
